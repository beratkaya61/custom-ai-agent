{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ™ï¸ Step 1: STT from Audio File using Whisper\n",
        "\n",
        "This notebook loads an audio file and transcribes it using OpenAI's Whisper model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“š Import the Whisper library\n",
        "import whisper\n",
        "import os\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Check if a GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ§  Load the Whisper model\n",
        "# Options: tiny, base, small, medium, large\n",
        "model = whisper.load_model(\"base\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: c:\\Users\\BERAT\\Desktop\\custom-ai-agent\n"
          ]
        }
      ],
      "source": [
        "# Get the current working directory\n",
        "current_directory = Path.cwd()\n",
        "print(f\"Current directory: {current_directory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Absolute path to audio file: c:\\Users\\BERAT\\Desktop\\custom-ai-agent\\audio\\harvard.wav\n"
          ]
        }
      ],
      "source": [
        "# Construct the absolute path to the audio file\n",
        "# ðŸ”Š Path to your audio file\n",
        "# Replace with your own file if needed\n",
        "\n",
        "AUDIO_PATH = current_directory / \"audio\" / \"harvard.wav\"\n",
        "\n",
        "print(f\"Absolute path to audio file: {AUDIO_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:\n",
            "\n",
            " The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham. Tacos al pastor are my favorite. A zestful food is the hot cross bun.\n"
          ]
        }
      ],
      "source": [
        "# Check if the audio file exists and transcribe it\n",
        "if not AUDIO_PATH.is_file():\n",
        "    print(f\"Audio file not found: {AUDIO_PATH}\")\n",
        "    result = None\n",
        "else:\n",
        "    # Load audio and resample to 16 kHz\n",
        "    audio_data, _ = librosa.load(\"audio/harvard.wav\", sr=16000)\n",
        "    audio_data = librosa.to_mono(audio_data) if audio_data.ndim > 1 else audio_data\n",
        "\n",
        "    # Ensure float32 dtype\n",
        "    audio_data = audio_data.astype(np.float32)\n",
        "\n",
        "    # Transcribe\n",
        "    result = model.transcribe(audio_data)\n",
        "\n",
        "    print(\"Transcription:\\n\")\n",
        "\n",
        "    print(result[\"text\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
