{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re\n",
    "from TTS.api import TTS\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "from langdetect import detect\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ada72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MBZUAI/LaMini-Flan-T5-783M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context Retriever\n",
    "def retrieve_context(query, docs, top_k=2):\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    doc_embeddings = embedder.encode(docs, convert_to_tensor=True)\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, doc_embeddings)[0]\n",
    "    top_results = torch.topk(similarities, k=top_k)\n",
    "    retrieved = [docs[i] for i in top_results.indices]\n",
    "    return ' '.join(retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fcd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer_with_comment_and_score(question, answer, context):\n",
    "    prompt = f\"\"\"You are a technical interviewer evaluating a candidate's response.\n",
    "You are given the job context, the interview question, and the candidate's answer.\n",
    "\n",
    "Job Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Write a short evaluation comment (1‚Äì2 sentences) about the quality of the candidate's answer and then give a score from 1 to 10.\n",
    "\n",
    "Format:\n",
    "Comment: <your comment>\n",
    "Score: <1‚Äì10>\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    print (f\"Decoded output: {decoded}\")\n",
    "    \n",
    "    # # üåü Regex-based extraction\n",
    "    # score_match = re.search(r'(\\b\\d{1,2}\\b)\\s*(?:out of 10|/10)?', decoded)\n",
    "    # score = int(score_match.group(1)) if score_match else None\n",
    "    \n",
    "    # # 2. Remove the score sentence to get the comment\n",
    "    # comment_part = re.split(r'I would rate.*|I‚Äôd rate.*|Score:.*', decoded, flags=re.IGNORECASE)\n",
    "    # comment = comment_part[0].strip() if comment_part else \"N/A\"\n",
    "    \n",
    "    # print (f\"Extracted comment: {comment}\")\n",
    "    # print (f\"Extracted score: {score}\")\n",
    "\n",
    "     # Try format: Comment: ... Score: ...\n",
    "    comment_match = re.search(r\"Comment:\\s*(.*?)\\s*Score:\", decoded, re.DOTALL)\n",
    "    score_match = re.search(r\"Score:\\s*(\\d{1,2})\", decoded)\n",
    "\n",
    "    if comment_match and score_match:\n",
    "        comment = comment_match.group(1).strip()\n",
    "        score = int(score_match.group(1))\n",
    "        return comment, score\n",
    "\n",
    "    # Try fallback: free-text sentence like \"I would rate the candidate's answer a 9 out of 10.\"\n",
    "    score_match = re.search(r\"\\b(?:rate.*?|\\bscore.*?)(\\d{1,2})\\s*(?:out of 10|/10)?\", decoded, re.IGNORECASE)\n",
    "    score = int(score_match.group(1)) if score_match else None\n",
    "\n",
    "    # Extract first sentence as comment, excluding rating phrases\n",
    "    rating_phrases = [\"I would rate\", \"I'd rate\", \"Score:\", \"I give\", \"My rating is\"]\n",
    "    for phrase in rating_phrases:\n",
    "        decoded = decoded.replace(phrase, \"\")\n",
    "\n",
    "    # Take first 1‚Äì2 sentences as comment\n",
    "    sentences = re.split(r'[.!?]\\s+', decoded.strip())\n",
    "    comment = \". \".join(sentences[:2]).strip()\n",
    "\n",
    "    print (f\"Extracted comment: {comment}\")\n",
    "    print (f\"Extracted score: {score}\")\n",
    "\n",
    "    return comment, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job Docs (RAG)\n",
    "job_docs = [\n",
    "    \"Python scripting, automation, data analysis using Pandas, NumPy, Matplotlib.\",\n",
    "    \"Experience with machine learning frameworks like scikit-learn, TensorFlow, Keras.\",\n",
    "    \"Object-oriented programming, version control, API interaction.\"\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Questions & Answers\n",
    "# -------------------------\n",
    "questions = [\n",
    "    \"Can you tell me about your experience with Python?\",\n",
    "    \"Describe your experience with machine learning.\",\n",
    "    \"How do you approach debugging complex software issues?\"\n",
    "]\n",
    "\n",
    "#  \"\"\"I first reproduce the issue, review logs, and isolate the failing component. \n",
    "#     Then I use tools like `pdb`, print statements, and logging. \n",
    "#     If it's async or multi-threaded, I use `threading` and `concurrent.futures` to track flow. \n",
    "#     I write unit tests to prevent regression.\"\"\"\n",
    "\n",
    "candidate_answers = [\n",
    "    \"\"\"My experience with Python is quite extensive, spanning several years across various domains. \n",
    "    I've used Python for scripting, automation, and data analysis, leveraging libraries like Pandas, NumPy, and Matplotlib. \n",
    "    I also have experience with web frameworks like Flask and Django for building RESTful APIs. \n",
    "    My work often involves writing clean, maintainable code and adhering to best practices in software development. \n",
    "    Additionally, I am familiar with version control systems like Git and have contributed to open-source projects.\"\"\",\n",
    "\n",
    "    \"\"\"I‚Äôve worked on multiple ML projects. One involved customer churn prediction using Random Forest and XGBoost. \n",
    "    I handled data cleaning, feature engineering, and model tuning. \n",
    "    I‚Äôve also built NLP pipelines for sentiment analysis using TF-IDF + Logistic Regression and LSTM. \n",
    "    I prefer TensorFlow and scikit-learn for most projects.\"\"\",\n",
    "\n",
    "   \"\"\"My knowledge on this subject is very limited.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Evaluation Loop\n",
    "results = []\n",
    "\n",
    "for q, a in zip(questions, candidate_answers):\n",
    "    ctx = retrieve_context(q, job_docs)\n",
    "    comment, score = evaluate_answer_with_comment_and_score(q, a, ctx)\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"answer\": a,\n",
    "        \"context\": ctx,\n",
    "        \"evaluation_comment\": comment,\n",
    "        \"score\": score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b51d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Results\n",
    "for idx, res in enumerate(results, 1):\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üî¢ Question {idx}: {res['question']}\\n\")\n",
    "    print(f\"üìù Candidate Answer:\\n{res['answer'].strip()}\\n\")\n",
    "    print(f\"üìÑ Retrieved Context:\\n{res['context']}\\n\")\n",
    "    print(f\"üß† Evaluation Comment:\\n{res['evaluation_comment']}\\n\")\n",
    "    print(f\"üìä Score: {res['score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map language to model\n",
    "\n",
    "LANG_TO_TTS_MODEL = {\n",
    "    \"en\": \"tts_models/en/ljspeech/tacotron2-DDC\",\n",
    "      \n",
    "    \"de\": \"tts_models/de/thorsten/tacotron2-DCA\",\n",
    "    \"fr\": \"tts_models/fr/mai/tacotron2-DDC\",\n",
    "    \"tr\": \"tts_models/tr/common-voice/glow-tts\",\n",
    "    \"es\": \"tts_models/es/mai/tacotron2-DDC\",\n",
    "    \"ja\": \"tts_models/ja/kokoro/tacotron2-DDC\",\n",
    "}\n",
    "\n",
    "# Detect language\n",
    "lang_code = detect(candidate_answers)\n",
    "print(f\"Detected Language: {lang_code}\")\n",
    "\n",
    "if lang_code in LANG_TO_TTS_MODEL:\n",
    "    tts_model_name = LANG_TO_TTS_MODEL[lang_code]\n",
    "    tts = TTS(tts_model_name)\n",
    "    tts.tts_to_file(text=candidate_answers, file_path=\"output.wav\")\n",
    "    print(\"‚úÖ Audio generated.\")\n",
    "    Audio(\"output.wav\")\n",
    "else:\n",
    "    print(f\"‚ùå No TTS model found for language '{lang_code}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
