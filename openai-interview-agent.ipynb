{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef6c29",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# -------------------------\n",
    "# Set your OpenAI API key\n",
    "# -------------------------\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7fd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Load Embedder\n",
    "# -------------------------\n",
    "embedder = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Job Docs\n",
    "# -------------------------\n",
    "job_docs = [\n",
    "    \"Python scripting, automation, data analysis using Pandas, NumPy, Matplotlib.\",\n",
    "    \"Experience with machine learning frameworks like scikit-learn, TensorFlow, Keras.\",\n",
    "    \"Object-oriented programming, version control, API interaction.\"\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Questions & Answers\n",
    "# -------------------------\n",
    "questions = [\n",
    "    \"Can you tell me about your experience with Python?\",\n",
    "    \"Describe your experience with machine learning.\",\n",
    "    \"How do you approach debugging complex software issues?\"\n",
    "]\n",
    "\n",
    "candidate_answers = [\n",
    "    \"\"\"My experience with Python is quite extensive, spanning several years across various domains. \n",
    "    I've used Python for scripting, automation, and data analysis, leveraging libraries like Pandas, NumPy, and Matplotlib. \n",
    "    I also have experience with web frameworks like Flask and Django for building RESTful APIs. \n",
    "    My work often involves writing clean, maintainable code and adhering to best practices in software development. \n",
    "    Additionally, I am familiar with version control systems like Git and have contributed to open-source projects.\"\"\",\n",
    "\n",
    "    \"\"\"I‚Äôve worked on multiple ML projects. One involved customer churn prediction using Random Forest and XGBoost. \n",
    "    I handled data cleaning, feature engineering, and model tuning. \n",
    "    I‚Äôve also built NLP pipelines for sentiment analysis using TF-IDF + Logistic Regression and LSTM. \n",
    "    I prefer TensorFlow and scikit-learn for most projects.\"\"\",\n",
    "\n",
    "    \"\"\"I first reproduce the issue, review logs, and isolate the failing component. \n",
    "    Then I use tools like `pdb`, print statements, and logging. \n",
    "    If it's async or multi-threaded, I use `threading` and `concurrent.futures` to track flow. \n",
    "    I write unit tests to prevent regression.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# GPT-3.5 Evaluation Function\n",
    "# -------------------------\n",
    "def evaluate_with_chatgpt(question, answer, context):\n",
    "    prompt = f\"\"\"You are a technical interviewer.\n",
    "\n",
    "Job Context:\n",
    "{context}\n",
    "\n",
    "Interview Question:\n",
    "{question}\n",
    "\n",
    "Candidate's Answer:\n",
    "{answer}\n",
    "\n",
    "Please evaluate the candidate's answer in a short, constructive sentence or two, and then give a numerical score from 1 to 10.\n",
    "\n",
    "Respond in the following format:\n",
    "Comment: <comment>\n",
    "Score: <score>\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful technical interviewer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=200,\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    content = response['choices'][0]['message']['content']\n",
    "    comment, score = \"N/A\", \"N/A\"\n",
    "    if \"Comment:\" in content and \"Score:\" in content:\n",
    "        parts = content.strip().split(\"Score:\")\n",
    "        comment = parts[0].replace(\"Comment:\", \"\").strip()\n",
    "        score = parts[1].strip()\n",
    "    return comment, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e305a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------\n",
    "# Context Retriever\n",
    "# -------------------------\n",
    "def retrieve_context(query, docs, top_k=2):\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    doc_embeddings = embedder.encode(docs, convert_to_tensor=True)\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, doc_embeddings)[0]\n",
    "    top_results = similarities.topk(top_k)\n",
    "    return ' '.join([docs[i] for i in top_results.indices])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2648633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Main Loop\n",
    "# -------------------------\n",
    "results = []\n",
    "for q, a in zip(questions, candidate_answers):\n",
    "    ctx = retrieve_context(q, job_docs)\n",
    "    comment, score = evaluate_with_chatgpt(q, a, ctx)\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"answer\": a,\n",
    "        \"context\": ctx,\n",
    "        \"evaluation_comment\": comment,\n",
    "        \"score\": score\n",
    "    })\n",
    "\n",
    "# -------------------------\n",
    "# Save to JSON\n",
    "# -------------------------\n",
    "with open(\"interview_gpt3.5_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# -------------------------\n",
    "# Print Results\n",
    "# -------------------------\n",
    "for idx, res in enumerate(results, 1):\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üî¢ Question {idx}: {res['question']}\\n\")\n",
    "    print(f\"üìù Candidate Answer:\\n{res['answer'].strip()}\\n\")\n",
    "    print(f\"üìÑ Retrieved Context:\\n{res['context']}\\n\")\n",
    "    print(f\"üß† Evaluation Comment:\\n{res['evaluation_comment']}\\n\")\n",
    "    print(f\"üìä Score: {res['score']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
