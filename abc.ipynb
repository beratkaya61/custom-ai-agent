{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb075f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util,CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f0b3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load bi-encoder for fast retrieval\n",
    "bi_encoder = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "# Load cross-encoder for reranking\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L6-v2', device=device)\n",
    "\n",
    "# -------------------------\n",
    "# Load Small Evaluator Model (FLAN-T5)\n",
    "# -------------------------\n",
    "\n",
    "evaluator_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\").to(device)\n",
    "evaluator_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# -------------------------\n",
    "# Example Job Docs (RAG)\n",
    "# -------------------------\n",
    "job_docs = [\n",
    "    \"Python scripting, automation, data analysis using Pandas, NumPy, Matplotlib.\",\n",
    "    \"Experience with machine learning frameworks like scikit-learn, TensorFlow, Keras.\",\n",
    "    \"Object-oriented programming, version control, API interaction.\"\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Questions & Answers\n",
    "# -------------------------\n",
    "questions = [\n",
    "    \"Can you tell me about your experience with Python?\",\n",
    "    \"Describe your experience with machine learning.\",\n",
    "    \"How do you approach debugging complex software issues?\"\n",
    "]\n",
    "\n",
    "candidate_answers = [\n",
    "    # Q1 Answer\n",
    "    \"\"\"My experience with Python is quite extensive, spanning several years across various domains. \n",
    "    I've used Python for scripting, automation, and data analysis, leveraging libraries like Pandas, NumPy, and Matplotlib. \n",
    "    I also have experience with web frameworks like Flask and Django for building RESTful APIs. \n",
    "    My work often involves writing clean, maintainable code and adhering to best practices in software development. \n",
    "    Additionally, I am familiar with version control systems like Git and have contributed to open-source projects.\"\"\",\n",
    "\n",
    "    # Q2 Answer\n",
    "    \"\"\"I‚Äôve worked on multiple ML projects. One involved customer churn prediction using Random Forest and XGBoost.\n",
    "    I preprocessed data with Pandas, engineered features, and used scikit-learn for model training.\"\"\",\n",
    "    \n",
    "    # Q3 Answer\n",
    "    \"\"\"I first reproduce the issue, review logs, and isolate the failing component. \n",
    "    Then I use tools like `pdb`, print statements, and logging. \n",
    "    If it's async or multi-threaded, I use `threading` and `concurrent.futures` to track flow.\n",
    "      I write unit tests to prevent regression.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc580d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# RAG Function\n",
    "# -------------------------\n",
    "\n",
    "# -------- Retrieval Function: Bi-Encoder + Cross-Encoder Reranking --------\n",
    "def retrieve_reranked_context(query, docs, top_k=2):\n",
    "\n",
    "    # Step 1: Embed query + docs using bi-encoder\n",
    "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "    doc_embeddings = bi_encoder.encode(docs, convert_to_tensor=True)\n",
    "\n",
    "    # Step 2: Get top-k based on cosine similarity\n",
    "    cos_scores  = util.pytorch_cos_sim(query_embedding, doc_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores , k=min(top_k * 3, len(docs)))\n",
    "\n",
    "    # Step 3: Rerank using cross-encoder\n",
    "    pairs = [(query, docs[idx]) for idx in top_results.indices]\n",
    "    rerank_scores = cross_encoder.predict(pairs)\n",
    "\n",
    "    # Step 4: Sort by rerank scores\n",
    "    reranked = sorted(zip(pairs, rerank_scores), key=lambda x: x[1], reverse=True)\n",
    "    top_contexts = [doc for (_, doc), _ in reranked[:top_k]]\n",
    "\n",
    "    return ' '.join(top_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "277aaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Evaluation Function --------\n",
    "\n",
    "def evaluate_with_flan(question, answer, context):\n",
    "    prompt = f\"\"\"\n",
    "    \n",
    "You are a professional technical interviewer.\n",
    "\n",
    "You are given:\n",
    "- A job Description\n",
    "- An interview question\n",
    "- A candidate's answer\n",
    "\n",
    "Job Description: {context}\n",
    "Interview Question: {question}\n",
    "Candidate Answer: {answer}\n",
    "\n",
    "Evaluate the candidate's answer based on relevance, depth, and accuracy.\n",
    "Respond ONLY in the following format:\n",
    "\n",
    "Comment: <1-2 sentence feedback on the answer quality>\n",
    "Score: <integer from 1 (poor) to 10 (excellent)>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    inputs = evaluator_tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    \n",
    "    output = evaluator_model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=180, # means we will generate up to 200 new tokens\n",
    "        # num_beams=4,   # means we will generate 4 different sequences and pick the best one\n",
    "        # early_stopping=True,    #means we will stop generating when we reach the end of the sequence\n",
    "        # do_sample=False,    # means we will not sample from the distribution, but take the most likely sequence\n",
    "        )\n",
    "    \n",
    "    decoded=evaluator_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print (f\"Decoded Output: {decoded}\")\n",
    "\n",
    "    # Post-process to extract comment and score\n",
    "\n",
    "    comment, score = \"\", \"\"\n",
    "    \n",
    "    for line in decoded.strip().splitlines():\n",
    "        if line.lower().startswith(\"comment:\"):\n",
    "            comment = line.split(\":\", 1)[-1].strip()\n",
    "        elif line.lower().startswith(\"score:\"):\n",
    "            score = line.split(\":\", 1)[-1].strip()\n",
    "\n",
    "    return comment, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aac73fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Output: 10\n",
      "Decoded Output: 10\n",
      "Decoded Output: 10\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Main Evaluation Loop\n",
    "# -------------------------\n",
    "results = []\n",
    "\n",
    "\n",
    "for q, a in zip(questions, candidate_answers):\n",
    "    ctx = retrieve_reranked_context(q, job_docs)\n",
    "    comment, score = evaluate_with_flan(q, a, ctx)\n",
    "\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"answer\": a,\n",
    "        \"context\": ctx,\n",
    "        \"comment\": comment,\n",
    "        \"score\": score     \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4b62e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Interview evaluation complete. Results saved to 'interview_results.json'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Save to JSON\n",
    "# -------------------------\n",
    "\n",
    "with open(\"interview_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Interview evaluation complete. Results saved to 'interview_results.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a7bc32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üî¢ Question 1: Can you tell me about your experience with Python?\n",
      "\n",
      "üìù Candidate Answer:\n",
      "My experience with Python is quite extensive, spanning several years across various domains. \n",
      "    I've used Python for scripting, automation, and data analysis, leveraging libraries like Pandas, NumPy, and Matplotlib. \n",
      "    I also have experience with web frameworks like Flask and Django for building RESTful APIs. \n",
      "    My work often involves writing clean, maintainable code and adhering to best practices in software development. \n",
      "    Additionally, I am familiar with version control systems like Git and have contributed to open-source projects.\n",
      "\n",
      "üìÑ Retrieved Context:\n",
      "Python scripting, automation, data analysis using Pandas, NumPy, Matplotlib. Experience with machine learning frameworks like scikit-learn, TensorFlow, Keras.\n",
      "\n",
      "üß† Evaluation Comment:\n",
      "\n",
      "\n",
      "‚≠ê Score: \n",
      "\n",
      "============================================================\n",
      "============================================================\n",
      "üî¢ Question 2: Describe your experience with machine learning.\n",
      "\n",
      "üìù Candidate Answer:\n",
      "I‚Äôve worked on multiple ML projects. One involved customer churn prediction using Random Forest and XGBoost.\n",
      "    I preprocessed data with Pandas, engineered features, and used scikit-learn for model training.\n",
      "\n",
      "üìÑ Retrieved Context:\n",
      "Experience with machine learning frameworks like scikit-learn, TensorFlow, Keras. Object-oriented programming, version control, API interaction.\n",
      "\n",
      "üß† Evaluation Comment:\n",
      "\n",
      "\n",
      "‚≠ê Score: \n",
      "\n",
      "============================================================\n",
      "============================================================\n",
      "üî¢ Question 3: How do you approach debugging complex software issues?\n",
      "\n",
      "üìù Candidate Answer:\n",
      "I first reproduce the issue, review logs, and isolate the failing component. \n",
      "    Then I use tools like `pdb`, print statements, and logging. \n",
      "    If it's async or multi-threaded, I use `threading` and `concurrent.futures` to track flow.\n",
      "      I write unit tests to prevent regression.\n",
      "\n",
      "üìÑ Retrieved Context:\n",
      "Object-oriented programming, version control, API interaction. Python scripting, automation, data analysis using Pandas, NumPy, Matplotlib.\n",
      "\n",
      "üß† Evaluation Comment:\n",
      "\n",
      "\n",
      "‚≠ê Score: \n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# -------- Display Results --------\n",
    "\n",
    "for idx, res in enumerate(results, 1):\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üî¢ Question {idx}: {res['question']}\\n\")\n",
    "    print(f\"üìù Candidate Answer:\\n{res['answer'].strip()}\\n\")\n",
    "    print(f\"üìÑ Retrieved Context:\\n{res['context'].strip()}\\n\")\n",
    "    print(f\"üß† Evaluation Comment:\\n{res['comment'].strip()}\\n\")\n",
    "    print(f\"‚≠ê Score: {res['score']}\\n\")\n",
    "    print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
