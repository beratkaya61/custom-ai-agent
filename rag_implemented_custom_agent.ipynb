{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "498db347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "280baede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load embedding  models\n",
    "# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight, fast, good for similarity\n",
    "\n",
    "# Load  model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(embedding_model)\n",
    "\n",
    "model = AutoModel.from_pretrained(embedding_model).to(device)\n",
    "\n",
    "# Evaluation model\n",
    "evaluator = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "611b5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example job-specific documents (replace with actual docs)\n",
    "job_docs = [\n",
    "    \"Python scripting, automation, data analysis using Pandas, NumPy, Matplotlib.\",\n",
    "    \"Experience with machine learning frameworks like scikit-learn, TensorFlow, Keras.\",\n",
    "    \"Object-oriented programming, version control, API interaction.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Questions to ask\n",
    "questions = [\n",
    "    \"Can you tell me about your experience with Python?\",\n",
    "    \"Describe your experience with machine learning.\",\n",
    "    \"How do you approach debugging complex software issues?\"\n",
    "]\n",
    "\n",
    "\n",
    "# Answers provided by the candidate\n",
    "candidate_answers = [\n",
    "    \"\"\"My experience with Python is quite extensive, spanning several years across various domains. I've primarily leveraged Python for its versatility in data analysis, machine learning, and automation.\n",
    "\n",
    "    In data analysis, I'm proficient with libraries like NumPy, Pandas, and Matplotlib. I've used them to clean, transform, analyze, and visualize complex datasets, extracting meaningful insights to inform decision-making.\n",
    "\n",
    "    For machine learning, I've worked extensively with scikit-learn, TensorFlow, and Keras. This includes building and deploying models for tasks such as classification, regression, clustering, and natural language processing. I'm comfortable with the entire ML pipeline, from data preprocessing and feature engineering to model training, evaluation, and hyperparameter tuning.\n",
    "\n",
    "    Beyond data science, I have strong experience in scripting and automation using Python. I've developed scripts for file manipulation, web scraping, API interactions, and automating repetitive tasks, significantly improving efficiency. I'm also familiar with object-oriented programming principles in Python and have experience with version control systems like Git.\"\"\",\n",
    "    \n",
    "    \"\"\"I’ve worked on multiple ML projects. One involved customer churn prediction using Random Forest and XGBoost. I handled data cleaning, feature engineering, and model tuning.\n",
    "\n",
    "    I’ve also built NLP pipelines for sentiment analysis using TF-IDF + Logistic Regression and LSTM. I prefer TensorFlow and scikit-learn for most projects.\"\"\",\n",
    "\n",
    "    \"\"\"I first reproduce the issue, review logs, and isolate the failing component. Then I use tools like `pdb`, print statements, and logging. If it's async or multi-threaded, I use `threading` and `concurrent.futures` to track flow. I write unit tests to prevent regression.\"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "interview_answer = \"\"\"My experience with Python is quite extensive, spanning several years across various domains. I've primarily leveraged Python for its versatility in data analysis, machine learning, and automation.\n",
    "\n",
    "In data analysis, I'm proficient with libraries like NumPy, Pandas, and Matplotlib. I've used them to clean, transform, analyze, and visualize complex datasets, extracting meaningful insights to inform decision-making.\n",
    "\n",
    "For machine learning, I've worked extensively with scikit-learn, TensorFlow, and Keras. This includes building and deploying models for tasks such as classification, regression, clustering, and natural language processing. I'm comfortable with the entire ML pipeline, from data preprocessing and feature engineering to model training, evaluation, and hyperparameter tuning.\n",
    "\n",
    "Beyond data science, I have strong experience in scripting and automation using Python. I've developed scripts for file manipulation, web scraping, API interactions, and automating repetitive tasks, significantly improving efficiency. I'm also familiar with object-oriented programming principles in Python and have experience with version control systems like Git.\n",
    "\n",
    "Overall, I'm confident in my ability to write clean, efficient, and well-documented Python code to solve a wide range of problems.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a45625e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Mean Pooling for embeddings\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return (token_embeddings * input_mask_expanded).sum(1) / input_mask_expanded.sum(1)\n",
    "\n",
    "# Get embedding\n",
    "def get_embedding(text):\n",
    "    encoded = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded)\n",
    "    return mean_pooling(model_output, encoded['attention_mask']).cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db179922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for documents\n",
    "\n",
    "doc_embeddings = [get_embedding(doc) for doc in job_docs]\n",
    "\n",
    "# doc_embeddings = embedding_model.encode(job_docs)\n",
    "\n",
    "# # Generate embeddings for questions\n",
    "# question_embeddings = embedding_model.encode(questions)\n",
    "\n",
    "# # Generate embedding for the interview answer\n",
    "# interview_answer_embedding = embedding_model.encode([interview_answer])[0]\n",
    "\n",
    "# # Calculate cosine similarity between the interview answer and job-specific documents\n",
    "# similarity_scores = cosine_similarity([interview_answer_embedding], doc_embeddings)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec7488ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG retrieval\n",
    "def rag_retrieve(query, top_k=2):\n",
    "    query_emb = get_embedding(query)\n",
    "    sims = [cosine_similarity([query_emb], [doc_emb])[0][0] for doc_emb in doc_embeddings]\n",
    "    top_indices = np.argsort(sims)[-top_k:][::-1]\n",
    "    return \" \".join([job_docs[i] for i in top_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97719b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate answer using Flan-T5\n",
    "def evaluate_answer(question, answer,context=None):\n",
    "    prompt = f\"\"\"You are a professional technical interviewer. \n",
    "You are given a job context, an interview question, and a candidate's answer.\n",
    "\n",
    "Job Context: {context}\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\n",
    "Return your comment and a score between 1 to 10.\"\"\"\n",
    "    return evaluator(prompt, max_new_tokens=128)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30bf47f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Results saved to 'interview_results.json'.\n"
     ]
    }
   ],
   "source": [
    "# Loop, perform RAG, evaluate, save\n",
    "results = []\n",
    "\n",
    "for question, answer in zip(questions, candidate_answers):\n",
    "    context = rag_retrieve(question)\n",
    "    evaluation = evaluate_answer(question, answer, context)\n",
    "    \n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"context\": context,\n",
    "        \"evaluation\": evaluation\n",
    "    })\n",
    "\n",
    "# Save results to JSON\n",
    "with open('interview_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Evaluation complete. Results saved to 'interview_results.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
